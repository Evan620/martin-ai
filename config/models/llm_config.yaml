# LLM Model Configurations for Ollama

# Available Models
models:
  llama:
    name: "llama3:70b"
    description: "Meta's Llama 3 70B - High capability general purpose model"
    use_cases:
      - "Complex policy analysis"
      - "Multi-document synthesis"
      - "Diplomatic text generation"
    parameters:
      temperature: 0.7
      top_p: 0.9
      top_k: 40
      max_tokens: 4096
      
  qwen:
    name: "qwen2.5:14b"
    description: "Alibaba's Qwen 2.5 14B - Efficient multilingual model"
    use_cases:
      - "Document processing"
      - "Information extraction"
      - "Quick analysis tasks"
    parameters:
      temperature: 0.7
      top_p: 0.9
      top_k: 40
      max_tokens: 2048

# Embedding Model
embeddings:
  nomic:
    name: "nomic-embed-text"
    description: "Nomic AI's embedding model - 768 dimensions"
    dimension: 768
    use_cases:
      - "Document embeddings"
      - "Semantic search"
      - "Knowledge base indexing"

# Default Model Selection
defaults:
  llm: "qwen"  # Default LLM for most tasks
  sensitive_llm: "qwen"  # For sensitive/sovereign data
  embeddings: "nomic"  # Default embedding model

# Model-specific settings
settings:
  retry_attempts: 3
  retry_delay: 2  # seconds
  timeout: 120  # seconds
  stream: false  # Enable streaming responses
